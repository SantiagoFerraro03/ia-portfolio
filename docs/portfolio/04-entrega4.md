<link rel="stylesheet" href="../custom.css">

# RegresiÃ³n Lineal y LogÃ­stica
## 2025-08-31

## Contexto
Se evaluaron 2 casos de negocio para el uso del modelo de regresiÃ³n lineal y del modelo de regresiÃ³n logÃ­stica. Primero, para la regresiÃ³n lineal se buscarÃ¡ estimar el valor medio de precio de casas para una inmobiliaria de Boston, y para la regresiÃ³n logÃ­stica se buscarÃ¡ hacer un diagnÃ³stico mÃ©dico para clasificar tumores en benignos o malignos.

## Objetivos
- Aprender a cargar y explorar datos.
- Implementar regresiÃ³n lineal paso a paso.
- Implementar regresiÃ³n logÃ­stica paso a paso.
- Interpretar resultados de forma simple.
- Evaluar la aplicaciÃ³n de los modelos en sus respectivos casos.

## Actividades (con tiempos estimados)
- InvestigaciÃ³n del caso â€” 15 min  
- InvestigaciÃ³n de los componentes (DocumentaciÃ³n) â€” 30 min  
- ElaboraciÃ³n del cÃ³digo â€” 25 min  
- AnÃ¡lisis de los resultados â€” 50 min  
- DocumentaciÃ³n de los hallazgos â€” 25 min  

## Desarrollo
Primero se leyÃ³ la documentaciÃ³n necesaria para el uso de los modelos, el uso y significado de las mÃ©tricas utilizadas, y la divisiÃ³n en partes de test y training data.  

Posteriormente, para cada caso se evaluÃ³ el contexto del negocio y se empezÃ³ la implementaciÃ³n del cÃ³digo.

Primero se hicieron las importaciones necesarias (setup):

```python hl_lines="2 6" linenums="1"
# Importar librerÃ­as que vamos a usar
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Para los modelos de machine learning
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score
from sklearn.datasets import load_breast_cancer

print("âœ… Setup completo!")
```

Luego se comenzÃ³ por el primer caso de negocio que fue el de la inmobiliaria de Boston, se cargÃ³ el dataset a partir de la URL, exploramos la forma de los datos, sus columnas, y nos centramos en separar los datos en X e y sobre la columna medv que es el precio de las casas que queremos predecir (extrayendo de los datos medv para X, y dejando solo medv para y):

```python hl_lines="2 6" linenums="1"
# === CARGAR DATOS DE CASAS EN BOSTON ===

# 1. Cargar el dataset desde una URL
url = "https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv"
boston_data = pd.read_csv(url)

print("ğŸ  DATASET: Boston Housing")
print(f"   ğŸ“Š Forma: {boston_data.shape}")
print(f"   ğŸ“‹ Columnas: {list(boston_data.columns)}")

# 2. Explorar los datos bÃ¡sicamente
print("\nğŸ” Primeras 5 filas:")
print(boston_data.head())

# 3. Preparar X (variables independientes) e y (variable dependiente)
# La columna 'medv' es el precio de la casa que queremos predecir
X = boston_data.drop('medv', axis=1)  # Todas las columnas EXCEPTO la que queremos predecir
y = boston_data['medv']                # Solo la columna que queremos predecir

print(f"\nğŸ“Š X tiene forma: {X.shape}")
print(f"ğŸ“Š y tiene forma: {y.shape}")
print(f"ğŸ¯ Queremos predecir: Precio de casas en miles de USD")
print(f"ğŸ“ˆ Precio mÃ­nimo: ${y.min():.1f}k, Precio mÃ¡ximo: ${y.max():.1f}k")
```

Posteriormente se dividieron los datos en test y train, entrenamos al modelo, hicimos las predicciones, y evaluamos el modelo en las distintas mÃ©tricas MAE, MSE, RMSE, RÂ², MAPE. Se obtuvieron ciertas interpretaciones a partir de dichas mÃ©tricas y se hizo una comparaciÃ³n de lo predicho para las primeras 5 casas vs el valor real.

```python hl_lines="2 6" linenums="1"
# === ENTRENAR MODELO DE REGRESIÃ“N LINEAL ===

# 1. Dividir datos en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"ğŸ“Š Datos de entrenamiento: {X_train.shape[0]} casas")
print(f"ğŸ“Š Datos de prueba: {X_test.shape[0]} casas")

# 2. Crear y entrenar el modelo
modelo_regresion = LinearRegression()
modelo_regresion.fit(X_train, y_train)

print("âœ… Modelo entrenado!")

# 3. Hacer predicciones
predicciones = modelo_regresion.predict(X_test)

print(f"\nğŸ”® Predicciones hechas para {len(predicciones)} casas")

# 4. Evaluar quÃ© tan bueno es el modelo con MÃšLTIPLES MÃ‰TRICAS
mae = mean_absolute_error(y_test, predicciones)
mse = mean_squared_error(y_test, predicciones)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, predicciones)

# Calcular MAPE manualmente
mape = np.mean(np.abs((y_test - predicciones) / y_test)) * 100

print(f"\nğŸ“ˆ MÃ‰TRICAS DE EVALUACIÃ“N:")
print(f"   ğŸ“Š MAE (Error Absoluto Medio): ${mae:.2f}k")
print(f"   ğŸ“Š MSE (Error CuadrÃ¡tico Medio): {mse:.2f}")
print(f"   ğŸ“Š RMSE (RaÃ­z del Error CuadrÃ¡tico): ${rmse:.2f}k")
print(f"   ğŸ“Š RÂ² (Coeficiente de determinaciÃ³n): {r2:.3f}")
print(f"   ğŸ“Š MAPE (Error Porcentual Absoluto): {mape:.1f}%")

print(f"\nğŸ” INTERPRETACIÃ“N:")
print(f"   ğŸ’° En promedio nos equivocamos por ${mae:.2f}k (MAE)")
print(f"   ğŸ“ˆ El modelo explica {r2*100:.1f}% de la variabilidad (RÂ²)")
print(f"   ğŸ“Š Error porcentual promedio: {mape:.1f}% (MAPE)")

# 5. Comparar algunas predicciones reales vs predichas
print(f"\nğŸ” EJEMPLOS (Real vs Predicho):")
for i in range(5):
    real = y_test.iloc[i]
    predicho = predicciones[i]
    print(f"   Casa {i+1}: Real ${real:.1f}k vs Predicho ${predicho:.1f}k")
```

Luego se continuÃ³ con el segundo caso de uso, los diagnÃ³sticos mÃ©dicos de cÃ¡ncer, en benigno o maligno, usando la regresiÃ³n logÃ­stica.

Primero se cargÃ³ el dataset y se convirtiÃ³ en DataFrame para ser mÃ¡s legible; se imprimieron ciertas caracterÃ­sticas como el nÃºmero de pacientes, las caracterÃ­sticas que tenÃ­amos y nuestro objetivo a predecir.

Por Ãºltimo se vio el balance de las clases, observando que hay mÃ¡s casos de cÃ¡ncer benignos que malignos, para ver las proporciones.

```python hl_lines="2 6" linenums="1"
# === CARGAR DATOS DE DIAGNÃ“STICO DE CÃNCER ===

# 1. Cargar el dataset de cÃ¡ncer de mama (que viene con sklearn)
cancer_data = load_breast_cancer()

# 2. Convertir a DataFrame para verlo mejor
X_cancer = pd.DataFrame(cancer_data.data, columns=cancer_data.feature_names)
y_cancer = cancer_data.target  # 0 = maligno, 1 = benigno

print("ğŸ¥ DATASET: Breast Cancer (DiagnÃ³stico)")
print(f"   ğŸ“Š Pacientes: {X_cancer.shape[0]}")
print(f"   ğŸ“Š CaracterÃ­sticas: {X_cancer.shape[1]}")
print(f"   ğŸ¯ Objetivo: Predecir si tumor es benigno (1) o maligno (0)")

# 3. Ver balance de clases
casos_malignos = (y_cancer == 0).sum()
casos_benignos = (y_cancer == 1).sum()

print(f"\nğŸ“Š DISTRIBUCIÃ“N:")
print(f"   âŒ Casos malignos: {casos_malignos}")
print(f"   âœ… Casos benignos: {casos_benignos}")
```

Por Ãºltimo, al igual que con el primer caso de uso, dividimos los datos en train y test, creamos y entrenamos el modelo de regresiÃ³n logÃ­stica, hicimos las predicciones y evaluamos mÃºltiples mÃ©tricas, en este caso de clasificaciÃ³n, como lo son accuracy, precision, recall y f1-score. Mostramos la matriz de confusiÃ³n con los VN, FP, FN y VP.

Generamos el classification report para obtener un reporte mÃ¡s detallado de las mÃ©tricas mencionadas y los promedios (avg). Se hicieron ciertas interpretaciones a partir de los datos obtenidos de las mÃ©tricas y, por Ãºltimo, llegamos a ver ciertos ejemplos especÃ­ficos de los primeros 5 pacientes: lo predicho versus la realidad.

```python hl_lines="2 6" linenums="1"
# === ENTRENAR MODELO DE CLASIFICACIÃ“N ===

# 1. Dividir datos en entrenamiento y prueba
X_train_cancer, X_test_cancer, y_train_cancer, y_test_cancer = train_test_split(
    X_cancer, y_cancer, test_size=0.2, random_state=42
)

print(f"ğŸ“Š Datos de entrenamiento: {X_train_cancer.shape[0]} pacientes")
print(f"ğŸ“Š Datos de prueba: {X_test_cancer.shape[0]} pacientes")

# 2. Crear y entrenar modelo de regresiÃ³n logÃ­stica
modelo_clasificacion = LogisticRegression(max_iter=5000, random_state=42)
modelo_clasificacion.fit(X_train_cancer, y_train_cancer)

print("âœ… Modelo de clasificaciÃ³n entrenado!")

# 3. Hacer predicciones
predicciones_cancer = modelo_clasificacion.predict(X_test_cancer)

# 4. Evaluar con MÃšLTIPLES MÃ‰TRICAS de clasificaciÃ³n
exactitud = accuracy_score(y_test_cancer, predicciones_cancer)
precision = precision_score(y_test_cancer, predicciones_cancer)
recall = recall_score(y_test_cancer, predicciones_cancer)
f1 = f1_score(y_test_cancer, predicciones_cancer)

print(f"\nğŸ“ˆ MÃ‰TRICAS DE CLASIFICACIÃ“N:")
print(f"   ğŸ¯ Exactitud (Accuracy): {exactitud:.3f} ({exactitud*100:.1f}%)")
print(f"   ğŸ¯ PrecisiÃ³n (Precision): {precision:.3f} ({precision*100:.1f}%)")
print(f"   ğŸ¯ Recall (Sensibilidad): {recall:.3f} ({recall*100:.1f}%)")
print(f"   ğŸ¯ F1-Score: {f1:.3f}")

# Mostrar matriz de confusiÃ³n de forma simple
matriz_confusion = confusion_matrix(y_test_cancer, predicciones_cancer)
print(f"\nğŸ”¢ MATRIZ DE CONFUSIÃ“N:")
print(f"   ğŸ“Š {matriz_confusion}")
print(f"   ğŸ“‹ [Verdaderos Negativos, Falsos Positivos]")
print(f"   ğŸ“‹ [Falsos Negativos, Verdaderos Positivos]")

# Reporte detallado
print(f"\nğŸ“‹ REPORTE DETALLADO:")
print(classification_report(y_test_cancer, predicciones_cancer, target_names=['Maligno', 'Benigno']))

print(f"\nğŸ” INTERPRETACIÃ“N MÃ‰DICA:")
print(f"   ğŸ©º Precision: De los casos que predecimos como benignos, {precision*100:.1f}% lo son realmente")
print(f"   ğŸ©º Recall: De todos los casos benignos reales, detectamos {recall*100:.1f}%")
print(f"   ğŸ©º F1-Score: Balance general entre precision y recall: {f1:.3f}")

# 5. Ver ejemplos especÃ­ficos
print(f"\nğŸ” EJEMPLOS (Real vs Predicho):")
for i in range(5):
    real = "Benigno" if y_test_cancer[i] == 1 else "Maligno"
    predicho = "Benigno" if predicciones_cancer[i] == 1 else "Maligno"
    print(f"   Paciente {i+1}: Real: {real} vs Predicho: {predicho}")
```

## Evidencias
![alt text](../assets/Entrega4Img0.png)
![alt text](../assets/Entrega4Img1.png)
![alt text](../assets/Entrega4Img2.png)
![alt text](../assets/Entrega4Img3.png)

[Collab](https://colab.research.google.com/drive/1WbL_Uz2sgvZYRXbqB-5cTVjz9RlNIj27?usp=sharing)

## InvestigaciÃ³n de MÃ©tricas

### MÃ©tricas de RegresiÃ³n
- MAE (Mean Absolute Error): Promedio de los errores absolutos sin importar si son positivos o negativos.  
- MSE (Mean Squared Error): Promedio de los errores al cuadrado, penaliza mÃ¡s los errores grandes.  
- RMSE (Root Mean Squared Error): RaÃ­z cuadrada del MSE, vuelve a las unidades originales del problema.  
- RÂ² (Coeficiente de DeterminaciÃ³n): Indica quÃ© porcentaje de la varianza es explicada por el modelo (0â€“1, donde 1 es perfecto).  
- MAPE (Mean Absolute Percentage Error): Error porcentual promedio, Ãºtil para comparar modelos con diferentes escalas.  

### MÃ©tricas de ClasificaciÃ³n
- Accuracy: Porcentaje de predicciones correctas sobre el total.  
- Precision: De todas las predicciones positivas, Â¿cuÃ¡ntas fueron realmente correctas?  
- Recall (Sensibilidad): De todos los casos positivos reales, Â¿cuÃ¡ntos detectamos?  
- F1-Score: Promedio armÃ³nico entre *precision* y *recall*.  
- Matriz de ConfusiÃ³n: Tabla que muestra predicciones vs valores reales.  

---

### ComparaciÃ³n entre RegresiÃ³n Lineal y RegresiÃ³n LogÃ­stica

| Aspecto             | RegresiÃ³n Lineal                                  | RegresiÃ³n LogÃ­stica                                                                 |
|---------------------|--------------------------------------------------|--------------------------------------------------------------------------------------|
| **QuÃ© predice**     | NÃºmeros continuos                                | CategorÃ­as                                                                           |
| **Ejemplo de uso**  | Determinar precios de autos segÃºn datos histÃ³ricos | Determinar si un paciente posee una enfermedad segÃºn su registro mÃ©dico              |
| **Rango de salida** | Cualquier valor real                             | 0 a 1 (probabilidad), luego clasificado segÃºn un umbral                             |
| **MÃ©trica principal** | MAE, MSE, RMSE, RÂ², MAPE                         | Accuracy, Precision, Recall, F1-Score, Matriz de ConfusiÃ³n                          |

## ReflexiÃ³n

### **Preguntas:**

**Â¿CuÃ¡l es la diferencia principal entre regresiÃ³n lineal y logÃ­stica?**

**Respuesta:** La regresiÃ³n lineal devuelve **valores continuos** (nÃºmeros reales), mientras que la regresiÃ³n logÃ­stica devuelve **probabilidades** que luego se asignan a categorÃ­as.

---

**Â¿Por quÃ© dividimos los datos en entrenamiento y prueba?**

**Respuesta:** Dividimos los datos en entrenamiento y prueba para **evitar el overfitting**. Si entrenamos el modelo con los mismos datos que usamos para probarlo, puede sobreajustarse a esa muestra especÃ­fica y no generalizar bien a datos nuevos. La separaciÃ³n permite evaluar el rendimiento real del modelo.

---

**Â¿QuÃ© significa una exactitud del 95%?**

**Respuesta:** Significa que el modelo **predice correctamente el 95% de los casos**.

---

**Â¿CuÃ¡l es mÃ¡s peligroso: predecir "benigno" cuando es "maligno", o al revÃ©s?**

**Respuesta:** Es mÃ¡s peligroso predecir "benigno" cuando en realidad es "maligno", porque se subestima un riesgo grave y no se toman las acciones necesarias para salvar una vida. Predecir "maligno" cuando es "benigno" solo provoca alarma innecesaria o pÃ©rdida de tiempo.

### **ReflexiÃ³n Final**  
Responde con tus propias palabras:

**Â¿CuÃ¡l modelo usarÃ­as para predecir el salario de un empleado?**

**Respuesta:** Dado que el salario es un valor **continuo**, usarÃ­a un modelo de **regresiÃ³n lineal**, porque nos da valores continuos. Las categorÃ­as de un modelo de regresiÃ³n logÃ­stica no serÃ­an aptas para este tipo de predicciones.

**Â¿CuÃ¡l modelo usarÃ­as para predecir si un email es spam?**

**Respuesta:** Dado que la predicciÃ³n es sobre **categorÃ­as**, usarÃ­a un modelo de **regresiÃ³n logÃ­stica**, ya que la regresiÃ³n lineal no es adecuada para este tipo de predicciones.

**Â¿Por quÃ© es importante separar datos de entrenamiento y prueba?**

**Respuesta:** Dividimos los datos en entrenamiento y prueba para **evitar el overfitting**. Si entrenamos el modelo con los mismos datos que usamos para probarlo, puede sobreajustarse a esa muestra especÃ­fica y no generalizar bien a datos nuevos. La separaciÃ³n permite evaluar el rendimiento real del modelo.

## Referencias
- https://juanfkurucz.com/ucu-ia/ut1/04-regresion-lineal-logistica/
- https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html
- https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html
- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html
- https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics
- https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html
- https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html
- https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html
- https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html
- https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html
